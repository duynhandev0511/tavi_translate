import streamlit as st
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM

# --- C·∫§U H√åNH V√Ä T·∫¢I MODEL ---

# ==============================================================================
# THAY TH·∫æ 'FiveC/tay-to-viet-v2' B·∫∞NG T√äN MODEL C·ª¶A B·∫†N N·∫æU C·∫¶N
# ==============================================================================
MODEL_NAME = "FiveC/tay-to-viet-v2"

# st.cache_resource gi√∫p l∆∞u tr·ªØ model v√†o cache, ch·ªâ t·∫£i 1 l·∫ßn duy nh·∫•t.
@st.cache_resource
def load_model():
    """T·∫£i tokenizer v√† model t·ª´ Hugging Face."""
    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)
        return tokenizer, model
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i model: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n model '{MODEL_NAME}' v√† k·∫øt n·ªëi m·∫°ng.")
        return None, None

# T·∫£i model v√† tokenizer
tokenizer, model = load_model()


# --- KH·ªûI T·∫†O SESSION STATE ---
# st.session_state gi√∫p l∆∞u tr·ªØ gi√° tr·ªã gi·ªØa c√°c l·∫ßn ch·∫°y l·∫°i c·ªßa app
# (v√≠ d·ª•: khi ng∆∞·ªùi d√πng nh·∫•n n√∫t).

# L∆∞u tr·ªØ vƒÉn b·∫£n d·ªãch g·∫ßn nh·∫•t
if 'translated_text' not in st.session_state:
    st.session_state.translated_text = ""
# L∆∞u tr·ªØ l·ªãch s·ª≠ c√°c b·∫£n d·ªãch
if 'history' not in st.session_state:
    st.session_state.history = []


# --- X√ÇY D·ª∞NG GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI) THEO M·∫™U GOOGLE TRANSLATE ---

st.set_page_config(layout="wide", page_title="D·ªãch m√°y T√†y - Vi·ªát", page_icon="ü§ñ")

# --- Ti√™u ƒë·ªÅ ---
st.markdown(
    """
    <style>
        /* T√πy ch·ªânh CSS ƒë·ªÉ gi·∫£m kho·∫£ng tr·ªëng tr√™n c√πng */
        .block-container {
            padding-top: 2rem;
        }
    </style>
    """,
    unsafe_allow_html=True
)
st.title("üáªüá≥ D·ªãch m√°y T√†y - Vi·ªát üáπ")
st.caption("M√¥ ph·ªèng giao di·ªán Google Translate v·ªõi model T√†y-Vi·ªát t·ª´ Hugging Face.")


# --- Khu v·ª±c d·ªãch ch√≠nh ---
col1, col2 = st.columns(2, gap="medium")

# C·ªôt Nh·∫≠p li·ªáu (B√™n tr√°i)
with col1:
    st.subheader("Ti·∫øng T√†y")
    input_text = st.text_area(
        "Nh·∫≠p vƒÉn b·∫£n c·∫ßn d·ªãch...",
        height=250,
        key="input_text_area",
        label_visibility="collapsed"
    )
    
    char_count = len(input_text)
    st.caption(f"{char_count} / 5000 k√Ω t·ª±")

    # N√∫t d·ªãch
    translate_button = st.button("D·ªãch sang Ti·∫øng Vi·ªát", type="primary", use_container_width=True)


# C·ªôt K·∫øt qu·∫£ (B√™n ph·∫£i)
with col2:
    st.subheader("Ti·∫øng Vi·ªát")
    # S·ª≠ d·ª•ng container v·ªõi vi·ªÅn ƒë·ªÉ t·∫°o box k·∫øt qu·∫£
    output_container = st.container(height=320, border=True)
    with output_container:
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong session_state
        st.markdown(st.session_state.translated_text)


# --- X·ª¨ L√ù LOGIC D·ªäCH ---
if translate_button:
    # Ch·ªâ th·ª±c hi·ªán d·ªãch n·∫øu model ƒë√£ t·∫£i v√† c√≥ vƒÉn b·∫£n nh·∫≠p v√†o
    if model and tokenizer and input_text:
        # Hi·ªÉn th·ªã spinner trong box k·∫øt qu·∫£ ƒë·ªÉ b√°o ƒëang x·ª≠ l√Ω
        with output_container:
            with st.spinner("üß† ƒêang d·ªãch..."):
                # 1. Tokenize c√¢u ƒë·∫ßu v√†o
                inputs = tokenizer(input_text, return_tensors="tf", max_length=512, truncation=True)
                
                # 2. D√πng model ƒë·ªÉ sinh ra c√¢u d·ªãch
                output_sequences = model.generate(
                    input_ids=inputs['input_ids'],
                    attention_mask=inputs['attention_mask'],
                    max_length=512,  # TƒÉng max_length cho c√¢u d√†i
                    num_beams=5,
                    early_stopping=True
                )
                
                # 3. Decode k·∫øt qu·∫£
                result = tokenizer.decode(output_sequences[0], skip_special_tokens=True)
                
                # 4. L∆∞u k·∫øt qu·∫£ v√†o session_state ƒë·ªÉ hi·ªÉn th·ªã
                st.session_state.translated_text = result
                
                # 5. Th√™m b·∫£n d·ªãch m·ªõi v√†o ƒë·∫ßu danh s√°ch l·ªãch s·ª≠
                st.session_state.history.insert(0, {
                    "source": input_text,
                    "translation": result
                })
                
                # Ch·∫°y l·∫°i script ƒë·ªÉ c·∫≠p nh·∫≠t UI v·ªõi k·∫øt qu·∫£ m·ªõi
                st.rerun()
                
    elif not input_text:
        st.toast("ü§î Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ d·ªãch!")
    else:
        st.error("Model ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·∫°i l·ªói ·ªü tr√™n v√† l√†m m·ªõi trang.")


# --- Khu v·ª±c L·ªãch s·ª≠ d·ªãch ---
st.divider()
st.header("L·ªãch s·ª≠")

if not st.session_state.history:
    st.info("Ch∆∞a c√≥ b·∫£n d·ªãch n√†o trong l·ªãch s·ª≠.")
else:
    # Hi·ªÉn th·ªã 5 b·∫£n d·ªãch g·∫ßn nh·∫•t
    for i, translation_item in enumerate(st.session_state.history[:5]):
        with st.container(border=True):
            st.text("T√†y (Ngu·ªìn)")
            st.info(translation_item["source"])

            st.text("Vi·ªát (D·ªãch)")
            st.success(translation_item["translation"])
